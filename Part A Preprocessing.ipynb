{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Preprocessing\n",
    "\n",
    "### **Authors:** oscardong4@gmail.com, thomas.oneil@sydney.edu.au & heeva.baharlou@sydney.edu.com (Dec 2024) - script adapted from [here](https://github.com/BodenmillerGroup/ImcSegmentationPipeline/blob/main/scripts/imc_preprocessing.ipynb)\n",
    "\n",
    "To fill in extra info\n",
    "\n",
    "\n",
    "## Order of the analysis\n",
    "1. MCD extraction\n",
    "2. Cellpose prep\n",
    "3. Cellpose model training\n",
    "4. Cellpose batch segmentation\n",
    "5. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting variables\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to your 'analysis' folder\n",
    "analysis = \"\"\n",
    "\n",
    "# Set this to your 'raw' folder\n",
    "raw = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCD extraction\n",
    "\n",
    "**MCD extraction**  \n",
    "<span style=\"color:grey; opacity: 0.5\">Cellpose prep</span>  \n",
    "<span style=\"color:grey; opacity: 0.5\">Cellpose model training</span>  \n",
    "<span style=\"color:grey; opacity: 0.5\">Cellpose batch segmentation</span>    \n",
    "<span style=\"color:grey; opacity: 0.5\">Feature Extraction</span>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasoneil/anaconda3/envs/imcsegpipe/lib/python3.9/site-packages/readimc/mcd_parser.py:131: UserWarning: Slide 0 corrupted: overlapping memory blocks for acquisitions 1 and 2\n",
      "  warn(\n",
      "ERROR:root:Error reading acquisition 5 from file 240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J.mcd: MCD file '240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J.mcd' corrupted: inconsistent acquisition image data size\n",
      "ERROR:root:Error reading acquisition 6 from file 240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J.mcd: MCD file '240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J.mcd' corrupted: inconsistent acquisition image data size\n",
      "/Users/thomasoneil/anaconda3/envs/imcsegpipe/lib/python3.9/site-packages/readimc/mcd_parser.py:131: UserWarning: Slide 0 corrupted: overlapping memory blocks for acquisitions 1 and 7\n",
      "  warn(\n",
      "/Users/thomasoneil/anaconda3/envs/imcsegpipe/lib/python3.9/site-packages/readimc/mcd_parser.py:131: UserWarning: Slide 0 corrupted: overlapping memory blocks for acquisitions 2 and 7\n",
      "  warn(\n",
      "/Users/thomasoneil/anaconda3/envs/imcsegpipe/lib/python3.9/site-packages/readimc/mcd_parser.py:131: UserWarning: Slide 0 corrupted: overlapping memory blocks for acquisitions 3 and 7\n",
      "  warn(\n",
      "/Users/thomasoneil/anaconda3/envs/imcsegpipe/lib/python3.9/site-packages/readimc/mcd_parser.py:131: UserWarning: Slide 0 corrupted: overlapping memory blocks for acquisitions 4 and 7\n",
      "  warn(\n",
      "/Users/thomasoneil/anaconda3/envs/imcsegpipe/lib/python3.9/site-packages/readimc/mcd_parser.py:131: UserWarning: Slide 0 corrupted: overlapping memory blocks for acquisitions 5 and 7\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import imcsegpipe\n",
    "from imcsegpipe.utils import sort_channels_by_mass\n",
    "\n",
    "# Logical variable for denoising\n",
    "denoise = True\n",
    "\n",
    "# Working directory storing all outputs\n",
    "work_dir = Path(analysis)\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Set and create output directories\n",
    "acquisitions_dir = work_dir / \"1a_extracted_mcd\"\n",
    "segment_dir = work_dir / \"1b_for_segmentation\"\n",
    "output_dir = work_dir / \"1c_full_images\"\n",
    "denoise_dir = work_dir / \"1d_denoise\" if denoise else None\n",
    "acquisitions_dir.mkdir(exist_ok=True)\n",
    "segment_dir.mkdir(exist_ok=True)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "if denoise:\n",
    "    denoise_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Raw directory with raw data files\n",
    "raw = Path(raw)\n",
    "\n",
    "# Step 1: Extract .mcd files\n",
    "temp_dirs = []\n",
    "try:\n",
    "    for raw_dir in [raw]:\n",
    "        zip_files = list(raw_dir.rglob(\"**/*.zip\"))\n",
    "        if len(zip_files) > 0:\n",
    "            temp_dir = TemporaryDirectory()\n",
    "            temp_dirs.append(temp_dir)\n",
    "            for zip_file in sorted(zip_files):\n",
    "                imcsegpipe.extract_zip_file(zip_file, temp_dir.name)\n",
    "    for raw_dir in [raw] + [Path(temp_dir.name) for temp_dir in temp_dirs]:\n",
    "        mcd_files = list(raw_dir.rglob(\"*.mcd\"))\n",
    "        mcd_files = [i for i in mcd_files if not i.stem.startswith('.')]\n",
    "        if len(mcd_files) > 0:\n",
    "            txt_files = list(raw_dir.rglob(\"*.txt\"))\n",
    "            txt_files = [i for i in txt_files if not i.stem.startswith('.')]\n",
    "            matched_txt_files = imcsegpipe.match_txt_files(mcd_files, txt_files)\n",
    "            for mcd_file in mcd_files:\n",
    "                imcsegpipe.extract_mcd_file(\n",
    "                    mcd_file,\n",
    "                    acquisitions_dir / mcd_file.stem,\n",
    "                    txt_files=matched_txt_files[mcd_file]\n",
    "                )\n",
    "finally:\n",
    "    for temp_dir in temp_dirs:\n",
    "        temp_dir.cleanup()\n",
    "    del temp_dirs\n",
    "\n",
    "# Read the panel.csv\n",
    "panel = pd.read_csv(raw / \"panel.csv\")\n",
    "\n",
    "# Step 2: Generate image stacks (_full and _segment) for 1b and 1c\n",
    "for acquisition_dir in acquisitions_dir.glob(\"[!.]*\"):\n",
    "    if acquisition_dir.is_dir():\n",
    "        imcsegpipe.create_analysis_stacks(\n",
    "            acquisition_dir=acquisition_dir,\n",
    "            analysis_dir=output_dir,\n",
    "            analysis_channels=sort_channels_by_mass(\n",
    "                panel.loc[panel[\"Full\"] == 1, \"Metal Tag\"].tolist()\n",
    "            ),\n",
    "            suffix=\"_full\",\n",
    "            hpf=50.0\n",
    "        )\n",
    "        imcsegpipe.create_analysis_stacks(\n",
    "            acquisition_dir=acquisition_dir,\n",
    "            analysis_dir=segment_dir,\n",
    "            analysis_channels=sort_channels_by_mass(\n",
    "                panel.loc[panel[\"Segment\"] == 1, \"Metal Tag\"].tolist()\n",
    "            ),\n",
    "            suffix=\"_segment\",\n",
    "            hpf=50.0\n",
    "        )\n",
    "\n",
    "# Step 3: Process TIFFs for denoising\n",
    "if denoise:\n",
    "    for sample_dir in acquisitions_dir.glob(\"[!.]*\"):\n",
    "        if sample_dir.is_dir():\n",
    "            for roi_tiff_path in sample_dir.glob(\"*.tiff\"):\n",
    "                roi_name = roi_tiff_path.stem\n",
    "                roi_subdir = denoise_dir / roi_name\n",
    "                roi_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Load the stack using tifffile\n",
    "                with tiff.TiffFile(roi_tiff_path) as tif:\n",
    "                    stack = tif.asarray()  # Load the entire TIFF stack as a NumPy array\n",
    "\n",
    "                # Filter and unstack based on panel.csv\n",
    "                for idx, row in panel[panel[\"Full\"] == 1].iterrows():\n",
    "                    metal_tag = row[\"Metal Tag\"]\n",
    "                    target = row[\"Target\"]\n",
    "                    output_name = f\"{metal_tag}-{target}_{metal_tag}.tiff\"\n",
    "                    output_path = roi_subdir / output_name\n",
    "\n",
    "                    # Extract the specific slice from the stack\n",
    "                    slice_image = stack[idx, :, :]  # Adjust indexing based on stack structure\n",
    "\n",
    "                    # Save the slice as a TIFF\n",
    "                    tiff.imwrite(output_path, slice_image.astype(np.uint16))  # Save as 16-bit TIFF\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested on Siddheshs data. Samples 1:3. Took 38 seconds on my Mac. 5GB output from 1.47GB input. Denoise outputs files labelled in accordance with IMC_Denoise pipeline (metaltag-marker_metaltag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cellpose preparation\n",
    "\n",
    "<strike>MCD extraction</strike>  \n",
    "**Cellpose prep**  \n",
    "<span style=\"color:grey; opacity: 0.5\">Cellpose model training</span>  \n",
    "<span style=\"color:grey; opacity: 0.5\">Cellpose batch segmentation</span>    \n",
    "<span style=\"color:grey; opacity: 0.5\">Feature Extraction</span>    \n",
    "\n",
    "Set your variables before running. Identify the `DNA` channel and the `square size` (in pixels) you want to use for cellpose training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = \"DNA\"\n",
    "square_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Targets: ['aSMA', 'CLA', 'anti-Cy3', 'CD68', 'CD163', 'CD183', 'FXIIIa', 'Ki67', 'anti-Biotin', 'anti-Cy5', 'CD3', 'CD206', 'HLA-DR', 'DNA', 'DNA']\n",
      "Image 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a2_ac_segment is smaller than the cropping size. Saved without cropping.\n",
      "Processed and cropped 240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J_s0_a2_ac_segment.\n",
      "Image 240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J_s0_a5_ac_segment is smaller than the cropping size. Saved without cropping.\n",
      "Processed and cropped 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a5_ac_segment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/tq0dp1p95rsfkwyjmhp757hr0000gn/T/ipykernel_9297/3693344009.py:66: UserWarning: /Users/thomasoneil/Library/CloudStorage/OneDrive-TheUniversityofSydney(Staff)/DROPBOX/siddhesh/analysis/2a_cellpose_full/300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a5_ac_segment_CpSeg.tiff is a low contrast image\n",
      "  io.imsave(im_output_path, composite_stack)\n",
      "/var/folders/h5/tq0dp1p95rsfkwyjmhp757hr0000gn/T/ipykernel_9297/3693344009.py:85: UserWarning: /Users/thomasoneil/Library/CloudStorage/OneDrive-TheUniversityofSydney(Staff)/DROPBOX/siddhesh/analysis/2b_cropped_images/300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a5_ac_segment_CpCrop.tiff is a low contrast image\n",
      "  io.imsave(crop_output_path, cropped)\n",
      "/var/folders/h5/tq0dp1p95rsfkwyjmhp757hr0000gn/T/ipykernel_9297/3693344009.py:85: UserWarning: /Users/thomasoneil/Library/CloudStorage/OneDrive-TheUniversityofSydney(Staff)/DROPBOX/siddhesh/analysis/2b_cropped_images/240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J_s0_a4_ac_segment_CpCrop.tiff is a low contrast image\n",
      "  io.imsave(crop_output_path, cropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and cropped 240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J_s0_a4_ac_segment.\n",
      "Processed and cropped 240824_Cohort_Study_SL3_H13-1010A_H13-1010B_H13-482C_s0_a1_ac_segment.\n",
      "Image 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a4_ac_segment is smaller than the cropping size. Saved without cropping.\n",
      "Image 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a3_ac_segment is smaller than the cropping size. Saved without cropping.\n",
      "Processed and cropped 240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J_s0_a3_ac_segment.\n",
      "Image 240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J_s0_a6_ac_segment is smaller than the cropping size. Saved without cropping.\n",
      "Processed and cropped 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a9_ac_segment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/tq0dp1p95rsfkwyjmhp757hr0000gn/T/ipykernel_9297/3693344009.py:85: UserWarning: /Users/thomasoneil/Library/CloudStorage/OneDrive-TheUniversityofSydney(Staff)/DROPBOX/siddhesh/analysis/2b_cropped_images/300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a9_ac_segment_CpCrop.tiff is a low contrast image\n",
      "  io.imsave(crop_output_path, cropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and cropped 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a6_ac_segment.\n",
      "Processed and cropped 240824_Cohort_Study_SL3_H13-1010A_H13-1010B_H13-482C_s0_a3_ac_segment.\n",
      "Processed and cropped 240824_Cohort_Study_SL3_H13-1010A_H13-1010B_H13-482C_s0_a4_ac_segment.\n",
      "Image 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a1_ac_segment is smaller than the cropping size. Saved without cropping.\n",
      "Processed and cropped 240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J_s0_a1_ac_segment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/tq0dp1p95rsfkwyjmhp757hr0000gn/T/ipykernel_9297/3693344009.py:85: UserWarning: /Users/thomasoneil/Library/CloudStorage/OneDrive-TheUniversityofSydney(Staff)/DROPBOX/siddhesh/analysis/2b_cropped_images/240824_Cohort_Study_SL2_H13-908B_H13-908A_H17-334J_s0_a1_ac_segment_CpCrop.tiff is a low contrast image\n",
      "  io.imsave(crop_output_path, cropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and cropped 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a8_ac_segment.\n",
      "Processed and cropped 300824_Cohort_Study_SL4_H16-794A_H16-794B_H17-350A_s0_a7_ac_segment.\n",
      "Processed and cropped 240824_Cohort_Study_SL3_H13-1010A_H13-1010B_H13-482C_s0_a2_ac_segment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/tq0dp1p95rsfkwyjmhp757hr0000gn/T/ipykernel_9297/3693344009.py:85: UserWarning: /Users/thomasoneil/Library/CloudStorage/OneDrive-TheUniversityofSydney(Staff)/DROPBOX/siddhesh/analysis/2b_cropped_images/240824_Cohort_Study_SL3_H13-1010A_H13-1010B_H13-482C_s0_a2_ac_segment_CpCrop.tiff is a low contrast image\n",
      "  io.imsave(crop_output_path, cropped)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, exposure, img_as_uint\n",
    "\n",
    "# Define directories\n",
    "dir_images = os.path.join(analysis, \"1b_for_segmentation\")\n",
    "im_output = os.path.join(analysis, \"2a_cellpose_full\")\n",
    "crop_output = os.path.join(analysis, \"2b_cropped_images\")\n",
    "panel_file = os.path.join(raw, \"panel.csv\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(im_output, exist_ok=True)\n",
    "os.makedirs(crop_output, exist_ok=True)\n",
    "\n",
    "# load image list\n",
    "image_list = [f for f in os.listdir(dir_images) if f.endswith(('.tiff', '.tif'))]\n",
    "\n",
    "# read panel\n",
    "panel = pd.read_csv(panel_file)\n",
    "segmentation_targets = panel.loc[panel['Segment'] == 1, 'Target'].tolist()\n",
    "print(\"Segmentation Targets:\", segmentation_targets)\n",
    "\n",
    "# get indices of dna channel\n",
    "dna_index = [i for i, target in enumerate(segmentation_targets) if target == dna]\n",
    "\n",
    "# crop and compress each image\n",
    "for image_file in image_list:\n",
    "    image_path = os.path.join(dir_images, image_file)\n",
    "    image = io.imread(image_path)\n",
    "    im_title = os.path.splitext(image_file)[0]\n",
    "    \n",
    "    # normalise\n",
    "    normalized_stack = []\n",
    "    for i in range(image.shape[0]): \n",
    "        channel = image[i, :, :]\n",
    "        normalized = exposure.rescale_intensity(channel, in_range='image', out_range=(0, 1))\n",
    "        normalized_stack.append(img_as_uint(normalized))\n",
    "    normalized_stack = np.stack(normalized_stack)\n",
    "    \n",
    "    # get dna channel\n",
    "    if dna_index:\n",
    "        # keep only the first instance of dna\n",
    "        dna_channel = normalized_stack[dna_index[0]]\n",
    "        \n",
    "        # remove dna from segmentation stack\n",
    "        for idx in sorted(dna_index, reverse=True):\n",
    "            normalized_stack = np.delete(normalized_stack, idx, axis=0)\n",
    "    else: #error message if dna not found\n",
    "        raise ValueError(\"DNA channel not found in segmentation targets.\")\n",
    "    \n",
    "    # create mask for surface segmentation\n",
    "    surface_mask = np.mean(normalized_stack, axis=0).astype(np.uint16)\n",
    "    \n",
    "    # create empty channel - for cellpose colour scheme to avoid red/green and combine in order empty > segment > dna\n",
    "    empty_channel = np.zeros_like(dna_channel, dtype=np.uint16)\n",
    "    empty -> surface mask -> DNA\n",
    "    composite_stack = np.stack([empty_channel, surface_mask, dna_channel])\n",
    "    \n",
    "    # save\n",
    "    im_output_path = os.path.join(im_output, f\"{im_title}_CpSeg.tiff\")\n",
    "    io.imsave(im_output_path, composite_stack)\n",
    "    \n",
    "    # get crop dimensions\n",
    "    height, width = composite_stack.shape[1:3]\n",
    "    if width < square_size or height < square_size:\n",
    "        # if image is smaller than crop size, save image itself as the crop\n",
    "        crop_output_path = os.path.join(crop_output, f\"{im_title}_CpCrop.tiff\")\n",
    "        io.imsave(crop_output_path, composite_stack)\n",
    "        print(f\"Image {im_title} is smaller than the cropping size. Saved without cropping.\")\n",
    "        continue\n",
    "\n",
    "    # create the crop and save\n",
    "    workable_x = width - square_size\n",
    "    workable_y = height - square_size\n",
    "    rand_x = random.randint(0, workable_x)\n",
    "    rand_y = random.randint(0, workable_y)\n",
    "    cropped = composite_stack[:, rand_y:rand_y + square_size, rand_x:rand_x + square_size]\n",
    "    crop_output_path = os.path.join(crop_output, f\"{im_title}_CpCrop.tiff\")\n",
    "    io.imsave(crop_output_path, cropped)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imcsegpipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
