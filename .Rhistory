# **** Assign cells from 'target' population to 'newTarget' based on 'value' of 'marker' being above/below 'direction' ****
# For example, reassign cells from 'T cell' population in to 'B' population if CD3 expression is greater than (>) 0.4
spe_subset = moveCells(spe_subset, target="T cell", newTarget="B cell", marker="CD3", value=0.4, direction=">")
# Make temporary column the new 'celltype' column
colData(spe_subset)$celltype = colData(spe_subset)$reassigned_celltype
colData(spe_subset)$reassigned_celltype = NULL
# Print updated UMAP with annotations (set 'do.label = FALSE' to remove labels)
UMAP_graph = dittoDimPlot(spe_subset, var = "celltype",
reduction.use = "UMAP", size = 1.2,
do.label = TRUE, labels.size = 2.5,
legend.size = 4) +
ggtitle("SOM clusters on UMAP, integrated cells")
UMAP_graph
ggsave(file.path("../ClustGraphs", "UMAP_labelled_annotated.png"), UMAP_graph, width = 6, height = 4.5)
# Save subsetted data with appropriate name.
saveRDS(spe_subset, "RDSFiles/spe_T_cells.rds")
# Create new population CSV for viewing in Mantis
celltype_info = colData(spe_subset)[, c("Image", "CellID", "celltype")] %>%
na.omit()
celltype_by_image = split(celltype_info, celltype_info$Image)
lapply(names(celltype_by_image), mantis_pop, suffix="_final_celltypes", cellSubs="celltype")
concat_df = data.frame()
for (x in list.files("mantis_CSVs", pattern = "_final_celltypes\\.csv$", full.names=TRUE)) {
tryCatch({
df = read.csv(x, header = FALSE)
cur_img = substr(x, 13, nchar(x) - 20)
df = cbind(Image = rep(cur_img, nrow(df)), df)
concat_df = rbind(concat_df, df)
}, error = function(e) {
})
}
write.table(concat_df, "../MantisProject/final_celltypes.csv", sep = ",", col.names = FALSE, row.names = FALSE)
require("BiocManager")
!require("BiocManager", quietly = TRUE)
!require("BiocManager")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
install.packages("xfun")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
library(tidyverse)
library(SpatialExperiment)
library(dittoSeq)
library(viridis)
library(RColorBrewer)
library(flowCore)
library(scater)
library(cowplot)
library(BiocSingular)
library(bluster)
library(ConsensusClusterPlus)
library(gridExtra)
library(tiff)
# Marker expression, other cellular features and spatial features (co-ordinates) are read and merged into a spatial experiment object
cells =  read.csv("CellProfilerOutput/cell.csv")
dt = readRDS("RDSFiles/IMCData.rds")
# Split data into marker intensities, metadata and co-ordinates
markers = colnames(dt)[8:(length(markers)+7)]
# Load CSVs
cells = read.csv("CellProfilerOutput/cell.csv")
panel = read.csv("../raw/panel.csv")
image = read.csv("CellProfilerOutput/Image.csv")
# Filter rows and columns
image = image %>%
mutate(ROI = 1, Image = str_remove(FileName_FullStack , "_full\\.tiff")) %>%
select(-FileName_FullStack)
panel = panel %>%
dplyr::filter(trimws(Target) != "") %>%
mutate(Metal = Metal.Tag) %>%
select("Metal", "Target") %>%
dplyr::filter(Metal != "Ir191")
# Join image data with cell data
cellsCombined = left_join(cells, image, by = join_by(ImageNumber))
# Define old name and what to change to.
rename_vec = c(
"Image" = "Image",
"ImageNumber" = "ImageID",
"ROI" = "ROI",
"ObjectNumber" = "CellID",
"AreaShape_Area" = "Area",
"AreaShape_Center_X" = "X",
"AreaShape_Center_Y" = "Y")
# Change names in cellsCombined from old names to new names
names(cellsCombined) = ifelse(names(cellsCombined) %in% names(rename_vec), rename_vec[names(cellsCombined)], names(cellsCombined))
# Name marker columns
markers <- panel[,"Target"]
createSortedVector <- function(n) {
numbers <- 1:n
char_numbers <- as.character(numbers)
sorted_char_numbers <- sort(char_numbers, method = "radix")
sorted_numbers <- as.integer(sorted_char_numbers)
return(sorted_numbers)
}
ordered_markers = markers[createSortedVector(length(markers))]
colnames(cellsCombined)[6:(length(markers)+5)] = ordered_markers
# Keep only desired columns
meta = unname(sapply(strsplit(rename_vec, " = "), '[', 1))
keep = c(meta,ordered_markers)
cellsCombined = cellsCombined %>% select(all_of(keep))
cellsCombined$X = as.integer(cellsCombined$X)
cellsCombined$Y = as.integer(cellsCombined$Y)
cellsCombined$Area = as.integer(cellsCombined$Area)
dir.create("RDSFiles", showWarnings = FALSE)
saveRDS(cellsCombined, "RDSFiles/IMCData.rds")
# Marker expression, other cellular features and spatial features (co-ordinates) are read and merged into a spatial experiment object
cells =  read.csv("CellProfilerOutput/cell.csv")
dt = readRDS("RDSFiles/IMCData.rds")
# Split data into marker intensities, metadata and co-ordinates
markers = colnames(dt)[8:(length(markers)+7)]
baseCol = colnames(dt)[!(colnames(dt) %in% markers)]
baseCol = setdiff(baseCol, c("X","Y"))
counts <- dt[, markers]
meta <- dt[, baseCol]
coords <- dt[, c("X", "Y")]
# Scale data back up (if processed through cell profiler)
counts = counts*65535
# Create spatial object
spe <- SpatialExperiment(assays = list(counts = t(counts)),
colData = meta,
sample_id = as.character(meta$ImageID),
spatialCoords = as.matrix(coords))
# Set DonorID (dummy variable here)
spe$DonorID = as.factor(spe$ImageID)
# Change variables to 'factor' type
spe$Image = as.factor(spe$Image)
spe$ImageID = as.factor(spe$ImageID)
spe$ROI = as.factor(spe$ROI)
colnames(spe) = paste0(spe$ImageID, "_", spe$CellID)
# Plot current distribution
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "counts", max=10) +
ggtitle("CD3 - before transformation")
# Plot distribution after arcsinh transforming data
assay(spe, "exprs") = asinh(counts(spe))
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "exprs", max = 10) +
ggtitle("CD3 - after arcsinh transformation")
### Scale (z-transform) the arcsinh-transformed data
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store scaled expressions
scaled_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(scaled_exprs_matrix) <- channels
colnames(scaled_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to scale
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Perform Z-normalization if there are enough non-NA values
scaled_data <- scale(channel_data)
scaled_exprs_matrix[channel, image_indices] <- scaled_data
}
}
# Assign the scaled data back to the assay
assay(spe, "scaled_exprs") <- scaled_exprs_matrix
# Simple min imputation example - this replaces NA values generated by Z-norm, with the min value of that channel across all images
exprs_data <- assay(spe, "scaled_exprs")
for (i in 1:ncol(exprs_data)) {
column_values <- exprs_data[, i]
exprs_data[is.na(column_values), i] <- min(column_values, na.rm = TRUE)
}
assay(spe, "scaled_exprs") <- exprs_data
# Plot distribution after z-transforming the data
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "scaled_exprs", max=5) + ggtitle("CD3 - after z-transformation")
### Normalise values between 0 and 1 for each image
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store normalized expressions
norm_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(norm_exprs_matrix) <- channels
colnames(norm_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to normalize
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Apply min-max normalization
min_val <- min(channel_data, na.rm = TRUE)
max_val <- max(channel_data, na.rm = TRUE)
# Avoid division by zero if all values in channel_data are the same
if (range_val != 0) {
norm_data <- (channel_data - min_val) / (max_val - min_val)
} else {
norm_data <- rep(0, length(channel_data))
}
norm_exprs_matrix[channel, image_indices] <- norm_data
}
}
# Marker expression, other cellular features and spatial features (co-ordinates) are read and merged into a spatial experiment object
cells =  read.csv("CellProfilerOutput/cell.csv")
dt = readRDS("RDSFiles/IMCData.rds")
# Split data into marker intensities, metadata and co-ordinates
markers = colnames(dt)[8:(length(markers)+7)]
baseCol = colnames(dt)[!(colnames(dt) %in% markers)]
baseCol = setdiff(baseCol, c("X","Y"))
counts <- dt[, markers]
meta <- dt[, baseCol]
coords <- dt[, c("X", "Y")]
# Scale data back up (if processed through cell profiler)
counts = counts*65535
# Create spatial object
spe <- SpatialExperiment(assays = list(counts = t(counts)),
colData = meta,
sample_id = as.character(meta$ImageID),
spatialCoords = as.matrix(coords))
# Set DonorID (dummy variable here)
spe$DonorID = as.factor(spe$ImageID)
# Change variables to 'factor' type
spe$Image = as.factor(spe$Image)
spe$ImageID = as.factor(spe$ImageID)
spe$ROI = as.factor(spe$ROI)
colnames(spe) = paste0(spe$ImageID, "_", spe$CellID)
# Plot current distribution
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "counts", max=10) +
ggtitle("CD3 - before transformation")
# Plot distribution after arcsinh transforming data
assay(spe, "exprs") = asinh(counts(spe))
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "exprs", max = 10) +
ggtitle("CD3 - after arcsinh transformation")
### Scale (z-transform) the arcsinh-transformed data
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store scaled expressions
scaled_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(scaled_exprs_matrix) <- channels
colnames(scaled_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to scale
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Perform Z-normalization if there are enough non-NA values
scaled_data <- scale(channel_data)
scaled_exprs_matrix[channel, image_indices] <- scaled_data
}
}
# Assign the scaled data back to the assay
assay(spe, "scaled_exprs") <- scaled_exprs_matrix
# Simple min imputation example - this replaces NA values generated by Z-norm, with the min value of that channel across all images
exprs_data <- assay(spe, "scaled_exprs")
for (i in 1:ncol(exprs_data)) {
column_values <- exprs_data[, i]
exprs_data[is.na(column_values), i] <- min(column_values, na.rm = TRUE)
}
assay(spe, "scaled_exprs") <- exprs_data
# Plot distribution after z-transforming the data
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "scaled_exprs", max=5) + ggtitle("CD3 - after z-transformation")
### Normalise values between 0 and 1 for each image
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store normalized expressions
norm_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(norm_exprs_matrix) <- channels
colnames(norm_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to normalize
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Apply min-max normalization
min_val <- min(channel_data, na.rm = TRUE)
max_val <- max(channel_data, na.rm = TRUE)
range_val <- max_val - min_val
# Avoid division by zero if all values in channel_data are the same
if (range_val != 0) {
norm_data <- (channel_data - min_val) / range_val
} else {
norm_data <- rep(0, length(channel_data))
}
norm_exprs_matrix[channel, image_indices] <- norm_data
}
}
# Assign the normalized data back to the assay
assay(spe, "norm_exprs") <- norm_exprs_matrix
# Plot distribution after normalising the data
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "norm_exprs", max=1.0) + ggtitle("CD3 - after normalising")
# Create an entry that specifies which markers are useful for clustering
forClust = markers
rowData(spe)$use_channel  <- rownames(spe) %in% forClust
### Assigning colour palettes
color_vectors <- list()
# DonorID
donor_ids <- unique(spe$DonorID)
# Create a color vector that repeats  if there are more than 12 unique DonorIDs
donor_colors <- brewer.pal(12, name = "Paired")[as.numeric(donor_ids) %% 12 + 1]
# Set the names of the colors to match the unique DonorIDs
DonorID <- setNames(donor_colors, donor_ids)
color_vectors$DonorID <- DonorID
# ImageID
image_ids <- unique(spe$ImageID)
# Create a color vector that repeats  if there are more than 12 unique ImageIDs
image_colors <- brewer.pal(12, name = "Paired")[as.numeric(image_ids) %% 12 + 1]
# Set the names of the colors to match the unique ImageIDs
ImageID <- setNames(image_colors, image_ids)
color_vectors$ImageID <- ImageID
metadata(spe)$color_vectors <- color_vectors
# Add a universal CellID column
colData(spe)$uCellID = 1:length(spe$CellID)
a = as.data.frame(colData(spe))
a = a %>%
group_by(Image) %>%
dplyr::filter(row_number()==1) %>%
select(Image, ImageID, uCellID)
# Write a csv with an ImageID to ImShort to Image name to uCellID key.
write.csv(a, "Image_uCellID_key.csv")
rm(a)
saveRDS(spe, "RDSFiles/spe.rds")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/HeevaData/analysis")
library(tidyverse)
library(SpatialExperiment)
library(dittoSeq)
library(viridis)
library(RColorBrewer)
library(flowCore)
library(scater)
library(cowplot)
library(BiocSingular)
library(bluster)
library(ConsensusClusterPlus)
library(gridExtra)
library(tiff)
# Load CSVs
cells = read.csv("CellProfilerOutput/cell.csv")
panel = read.csv("../raw/panel.csv")
image = read.csv("CellProfilerOutput/Image.csv")
# Filter rows and columns
image = image %>%
mutate(ROI = 1, Image = str_remove(FileName_FullStack , "_full\\.tiff")) %>%
select(-FileName_FullStack)
panel = panel %>%
dplyr::filter(trimws(Target) != "") %>%
mutate(Metal = Metal.Tag) %>%
select("Metal", "Target") %>%
dplyr::filter(Metal != "Ir191")
# Join image data with cell data
cellsCombined = left_join(cells, image, by = join_by(ImageNumber))
# Define old name and what to change to.
rename_vec = c(
"Image" = "Image",
"ImageNumber" = "ImageID",
"ROI" = "ROI",
"ObjectNumber" = "CellID",
"AreaShape_Area" = "Area",
"AreaShape_Center_X" = "X",
"AreaShape_Center_Y" = "Y")
# Change names in cellsCombined from old names to new names
names(cellsCombined) = ifelse(names(cellsCombined) %in% names(rename_vec), rename_vec[names(cellsCombined)], names(cellsCombined))
# Name marker columns
markers <- panel[,"Target"]
createSortedVector <- function(n) {
numbers <- 1:n
char_numbers <- as.character(numbers)
sorted_char_numbers <- sort(char_numbers, method = "radix")
sorted_numbers <- as.integer(sorted_char_numbers)
return(sorted_numbers)
}
ordered_markers = markers[createSortedVector(length(markers))]
colnames(cellsCombined)[6:(length(markers)+5)] = ordered_markers
# Keep only desired columns
meta = unname(sapply(strsplit(rename_vec, " = "), '[', 1))
keep = c(meta,ordered_markers)
cellsCombined = cellsCombined %>% select(all_of(keep))
cellsCombined$X = as.integer(cellsCombined$X)
cellsCombined$Y = as.integer(cellsCombined$Y)
cellsCombined$Area = as.integer(cellsCombined$Area)
dir.create("RDSFiles", showWarnings = FALSE)
saveRDS(cellsCombined, "RDSFiles/IMCData.rds")
# Marker expression, other cellular features and spatial features (co-ordinates) are read and merged into a spatial experiment object
dt = readRDS("RDSFiles/IMCData.rds")
# Split data into marker intensities, metadata and co-ordinates
markers = colnames(dt)[8:(length(markers)+7)]
baseCol = colnames(dt)[!(colnames(dt) %in% markers)]
baseCol = setdiff(baseCol, c("X","Y"))
counts <- dt[, markers]
meta <- dt[, baseCol]
coords <- dt[, c("X", "Y")]
# Scale data back up (if processed through cell profiler)
counts = counts*65535
# Create spatial object
spe <- SpatialExperiment(assays = list(counts = t(counts)),
colData = meta,
sample_id = as.character(meta$ImageID),
spatialCoords = as.matrix(coords))
# Set DonorID (dummy variable here)
spe$DonorID = as.factor(spe$ImageID)
# Change variables to 'factor' type
spe$Image = as.factor(spe$Image)
spe$ImageID = as.factor(spe$ImageID)
spe$ROI = as.factor(spe$ROI)
colnames(spe) = paste0(spe$ImageID, "_", spe$CellID)
# Plot current distribution
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "counts", max=10) +
ggtitle("CD3 - before transformation")
# Plot distribution after arcsinh transforming data
assay(spe, "exprs") = asinh(counts(spe))
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "exprs", max = 10) +
ggtitle("CD3 - after arcsinh transformation")
### Scale (z-transform) the arcsinh-transformed data
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store scaled expressions
scaled_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(scaled_exprs_matrix) <- channels
colnames(scaled_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to scale
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Perform Z-normalization if there are enough non-NA values
scaled_data <- scale(channel_data)
scaled_exprs_matrix[channel, image_indices] <- scaled_data
}
}
# Assign the scaled data back to the assay
assay(spe, "scaled_exprs") <- scaled_exprs_matrix
# Simple min imputation example - this replaces NA values generated by Z-norm, with the min value of that channel across all images
exprs_data <- assay(spe, "scaled_exprs")
for (i in 1:ncol(exprs_data)) {
column_values <- exprs_data[, i]
exprs_data[is.na(column_values), i] <- min(column_values, na.rm = TRUE)
}
assay(spe, "scaled_exprs") <- exprs_data
# Plot distribution after z-transforming the data
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "scaled_exprs", max=5) + ggtitle("CD3 - after z-transformation")
### Normalise values between 0 and 1 for each image
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store normalized expressions
norm_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(norm_exprs_matrix) <- channels
colnames(norm_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to normalize
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Apply min-max normalization
min_val <- min(channel_data, na.rm = TRUE)
max_val <- max(channel_data, na.rm = TRUE)
range_val <- max_val - min_val
# Avoid division by zero if all values in channel_data are the same
if (range_val != 0) {
norm_data <- (channel_data - min_val) / range_val
} else {
norm_data <- rep(0, length(channel_data))
}
norm_exprs_matrix[channel, image_indices] <- norm_data
}
}
# Assign the normalized data back to the assay
assay(spe, "norm_exprs") <- norm_exprs_matrix
# Plot distribution after normalising the data
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "norm_exprs", max=1.0) + ggtitle("CD3 - after normalising")
# Create an entry that specifies which markers are useful for clustering
forClust = markers
rowData(spe)$use_channel  <- rownames(spe) %in% forClust
### Assigning colour palettes
color_vectors <- list()
# DonorID
donor_ids <- unique(spe$DonorID)
# Create a color vector that repeats  if there are more than 12 unique DonorIDs
donor_colors <- brewer.pal(12, name = "Paired")[as.numeric(donor_ids) %% 12 + 1]
# Set the names of the colors to match the unique DonorIDs
DonorID <- setNames(donor_colors, donor_ids)
color_vectors$DonorID <- DonorID
# ImageID
image_ids <- unique(spe$ImageID)
# Create a color vector that repeats  if there are more than 12 unique ImageIDs
image_colors <- brewer.pal(12, name = "Paired")[as.numeric(image_ids) %% 12 + 1]
# Set the names of the colors to match the unique ImageIDs
ImageID <- setNames(image_colors, image_ids)
color_vectors$ImageID <- ImageID
metadata(spe)$color_vectors <- color_vectors
# Add a universal CellID column
colData(spe)$uCellID = 1:length(spe$CellID)
a = as.data.frame(colData(spe))
a = a %>%
group_by(Image) %>%
dplyr::filter(row_number()==1) %>%
select(Image, ImageID, uCellID)
# Write a csv with an ImageID to ImShort to Image name to uCellID key.
write.csv(a, "Image_uCellID_key.csv")
rm(a)
saveRDS(spe, "RDSFiles/spe.rds")
View(cellsCombined)
