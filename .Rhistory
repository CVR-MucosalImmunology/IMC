dir.create(paste0("../MantisProject/", cur_img), showWarnings = FALSE)
cur_tiff = readTIFF(paste0("full_images/", tiffs[x]), all=TRUE)
cur_csv = read.csv(paste0("full_images/", csvs[x]), header=FALSE)$V1
for (channel in seq_along(cur_tiff)) {
metal_tag = cur_csv[channel]
marker = panel$Target[panel$Metal.Tag == metal_tag]
filename = paste0("../MantisProject/", cur_img, "/", marker, ".tiff")
mat = cur_tiff[[channel]]*65535
writeTIFF((mat-min(mat))/(max(mat)-min(mat)), filename)
}
}
seg_list = list.files("segmentation_masks", pattern = "\\.tif$", full.names = TRUE)
for (x in seg_list) {
cur_img = substr(x, 20, nchar(x) - 23)
from = x
to = paste0("../MantisProject/", cur_img, "/SegmentationFile.tif")
file.copy(from, to)
}
concat_df = data.frame()
for (x in list.files("mantis_CSVs", pattern = "_counts\\.csv$", full.names=TRUE)) {
cur_img = substr(x, 13, nchar(x) - 11)
df = read.csv(x) %>%
dplyr::rename(`Segment ID` = label)
df = cbind(`Image Folder Name` = rep(cur_img, nrow(df)), df)
concat_df = rbind(concat_df, df)
}
write.csv(concat_df, "../MantisProject/marker_counts.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
# Load in 'spe' object
spe = readRDS("RDSFiles/spe.rds")
#Remove celltype column if exists
colData(spe)$celltype_flowjo = NULL
# Read in spreadsheets from export folder and store in a list
temp = list.files(path = "../FlowJo/exports", pattern = "*.csv", full.names = TRUE)
temp = lapply(temp, function(x) {
name = basename(x)
name = as.character(name)
a = read.csv(x, header = T)
a = as.data.frame(a)
celltype = sub("\\.csv$", "", name)
a$celltype_flowjo = rep(celltype, nrow(a))
return(a)
})
# Merge the list into a single dataframe by binding rows.
data_raw = bind_rows(temp)
rm(temp)
data_raw = as.data.frame(data_raw)
data_raw$celltype_flowjo = as.factor(data_raw$celltype_flowjo)
# Remove duplicate entries by choosing one from them (eg. prioritise APCs)
data_raw <- data_raw %>%
group_by(uCellID) %>%
# arrange(celltype_flowjo != "APC", .by_group = TRUE) %>%
dplyr::filter(!duplicated(uCellID)) %>%
ungroup() %>%
select(uCellID, celltype_flowjo)
# Merge 'celltype_flowjo' into 'spe' metadata
metadata = as.data.frame(colData(spe))
metadata <- left_join(metadata, data_raw, by = c("uCellID"))
# Update the metadata in 'spe'
colData(spe)$celltype_flowjo <- metadata$celltype_flowjo
saveRDS(spe, "RDSFiles/spe.rds")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
# Run after importing FlowJo annotations - will write a '_FlowJo_celltypes.csv' file
celltype_info = colData(spe)[, c("Image", "CellID", "celltype_flowjo")] %>%
na.omit()
celltype_by_image = split(celltype_info, celltype_info$Image)
lapply(names(celltype_by_image), mantis_pop, suffix="_FlowJo_celltypes", cellSubs="celltype_flowjo")
concat_df = data.frame()
for (x in list.files("mantis_CSVs", pattern = "_FlowJo_celltypes\\.csv$", full.names=TRUE)) {
tryCatch({
df = read.csv(x, header = FALSE)
cur_img = substr(x, 13, nchar(x) - 21)
df = cbind(Image = rep(cur_img, nrow(df)), df)
concat_df = rbind(concat_df, df)
}, error = function(e) {
})
}
write.table(concat_df, "../MantisProject/FlowJo_celltypes.csv", sep = ",", col.names = FALSE, row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
## Run all code below.  For comments encased in '**** ****', read the comments and make any required changes to code below before running it.
# **** Select the population (from your FlowJo populations) you wish to cluster on ****
pop_to_cluster = "T-Cells"
## **** Variables: ****
#   - Maximum clusters for CCP function to generate
maxClust = 30
#   - Cluster number used or analysis (must be less than maxClust)
clustNumber = 12
#   - Markers for clustering (note all markers are used by default)
forClust = c("CD45RO", "CD8", "CD45", "CXCR3",
"CCR7", "CCR6", "Ki67",
"CD69", "CD3", "CD4", "HLADR")
spe = readRDS("RDSFiles/spe.rds")
## **** FlowSOM clustering on Spatial Object 'spe' ****
#   - If wanting to cluster on a subset of cells, specify the celltype_column (eg. 'celltype_flowjo') and and celltype_values (eg. 'T cell')
#   - To use a subset of markers for clustering, specify the subset in forClust above and set 'clustMarkers = forClust
#   - If wanting to batch correct (using Harmony specify the column which indicates unique batches
clustOut = harmonySOM(spe,
celltype_column = "celltype_flowjo",
celltype_values = pop_to_cluster,
clustMarkers = forClust,
batchCol = NULL)
# Cluster the 100 SOM codes into larger clusters
ccp = ConsensusClusterPlus(t(clustOut[[1]]$objects$som$codes[[1]]),
maxK = maxClust,
reps = 100,
distance = "euclidean",
seed = 220410,
plot = NULL)
# Visualize delta area plot
CATALYST:::.plot_delta_area(ccp)
# Save UMAP, Heatmap, and Z-score graphs to 'ClustGraphs' using clustering results
dir.create("../ClustGraphs", showWarnings = FALSE)
spe_subset = clustGraphs(clustOut, ccp, clustNumber, "All", TRUE, "../ClustGraphs")
# Generate UMAP of individual marker expression values and save to 'ClustGraphs'
png(file.path(getwd(), "../ClustGraphs", "markerPlots.png"), width = 3000, height = 3000, res = 300)
plot_list_harmony = multi_dittoDimPlot(spe_subset, var=rownames(spe_subset), reduction.use= "UMAP", assay = "norm_exprs", size = 0.2, list.out = TRUE)
plot_list_harmony <- lapply(plot_list_harmony, function(x) x + scale_color_viridis())
print(plot_grid(plotlist = plot_list_harmony))
dev.off()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
# Merge 'spe_subset' labels back into main 'spe' object and export for Mantis viewing
sMetadata = as.data.frame(colData(spe_subset))
sMetadata <- sMetadata %>% select(uCellID, som_clusters_corrected)
metadata = as.data.frame(colData(spe))
metadata$celltype <- NULL
metadata <- left_join(metadata, sMetadata, by = c("uCellID"))
colData(spe)$celltype <- metadata$som_clusters_corrected
# Export unique celltypes in 'celltype' column as a '_final_celltypes.csv' file
celltype_info = colData(spe)[, c("Image", "CellID", "celltype")] %>% na.omit()
celltype_by_image = split(celltype_info, droplevels(celltype_info$Image))
lapply(names(celltype_by_image), mantis_pop, suffix="_final_celltypes", cellSubs="celltype")
concat_df = data.frame()
for (x in list.files("mantis_CSVs", pattern = "_final_celltypes\\.csv$", full.names=TRUE)) {
tryCatch({
df = read.csv(x, header = FALSE)
cur_img = substr(x, 13, nchar(x) - 20)
df = cbind(Image = rep(cur_img, nrow(df)), df)
concat_df = rbind(concat_df, df)
}, error = function(e) {
})
}
write.table(concat_df, "../MantisProject/final_celltypes.csv", sep = ",", col.names = FALSE, row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
## If you wish to rename clusters (eg. 1 is " T cell"), run his chunk to overwrite the '_final_celltypes.csv' file from above
# **** Enter names of clusters on right side then run this code - delete rows you don't need if you ran fewer clusters ****
som_clusters_corrected = recode(spe_subset$som_clusters_corrected,
"1" = "T cell",
"2" = "B cell",
"3" = "C",
"4" = "D",
"5" = "E",
"6" = "F",
"7" = "G",
"8" = "H",
"9" = "I",
"10" = "J",
"11" = "K",
"12" = "L")
# Change current 'celltype' column
spe_subset$celltype = som_clusters_corrected
# Export unique celltypes in 'celltype' column as a '_final_celltypes.csv' file
celltype_info = colData(spe_subset)[, c("Image", "CellID", "celltype")] %>% na.omit()
celltype_by_image = split(celltype_info, droplevels(celltype_info$Image))
lapply(names(celltype_by_image), mantis_pop, suffix="_final_celltypes", cellSubs="celltype")
concat_df = data.frame()
for (x in list.files("mantis_CSVs", pattern = "_final_celltypes\\.csv$", full.names=TRUE)) {
tryCatch({
df = read.csv(x, header = FALSE)
cur_img = substr(x, 13, nchar(x) - 20)
df = cbind(Image = rep(cur_img, nrow(df)), df)
concat_df = rbind(concat_df, df)
}, error = function(e) {
})
}
write.table(concat_df, "../MantisProject/final_celltypes.csv", sep = ",", col.names = FALSE, row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
## If you wish to re-assign certain cells to a different population, run this chunk
# **** Visualise marker expression for a celltype to determine an appropriate cut off for reassigning cells using 'moveCells' function on next line ****
# For example, here 'T cell' entries in are evaluated for 'CD3' expression with a cut-off of 0.4
visMarker(spe_subset, "T cell", "CD3", 0.4)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
# **** Assign cells from 'target' population to 'newTarget' based on 'value' of 'marker' being above/below 'direction' ****
# For example, reassign cells from 'T cell' population in to 'B' population if CD3 expression is greater than (>) 0.4
spe_subset = moveCells(spe_subset, target="T cell", newTarget="B cell", marker="CD3", value=0.4, direction=">")
# Make temporary column the new 'celltype' column
colData(spe_subset)$celltype = colData(spe_subset)$reassigned_celltype
colData(spe_subset)$reassigned_celltype = NULL
# Print updated UMAP with annotations (set 'do.label = FALSE' to remove labels)
UMAP_graph = dittoDimPlot(spe_subset, var = "celltype",
reduction.use = "UMAP", size = 1.2,
do.label = TRUE, labels.size = 2.5,
legend.size = 4) +
ggtitle("SOM clusters on UMAP, integrated cells")
UMAP_graph
ggsave(file.path("../ClustGraphs", "UMAP_labelled_annotated.png"), UMAP_graph, width = 6, height = 4.5)
# Save subsetted data with appropriate name.
saveRDS(spe_subset, "RDSFiles/spe_T_cells.rds")
# Create new population CSV for viewing in Mantis
celltype_info = colData(spe_subset)[, c("Image", "CellID", "celltype")] %>%
na.omit()
celltype_by_image = split(celltype_info, celltype_info$Image)
lapply(names(celltype_by_image), mantis_pop, suffix="_final_celltypes", cellSubs="celltype")
concat_df = data.frame()
for (x in list.files("mantis_CSVs", pattern = "_final_celltypes\\.csv$", full.names=TRUE)) {
tryCatch({
df = read.csv(x, header = FALSE)
cur_img = substr(x, 13, nchar(x) - 20)
df = cbind(Image = rep(cur_img, nrow(df)), df)
concat_df = rbind(concat_df, df)
}, error = function(e) {
})
}
write.table(concat_df, "../MantisProject/final_celltypes.csv", sep = ",", col.names = FALSE, row.names = FALSE)
require("BiocManager")
!require("BiocManager", quietly = TRUE)
!require("BiocManager")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
install.packages("xfun")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/daniel.buffa/OneDrive - Westmead Institute for Medical Research/Desktop/Oscar/LizAnalysis/analysis")
library(tidyverse)
library(SpatialExperiment)
library(dittoSeq)
library(viridis)
library(RColorBrewer)
library(flowCore)
library(scater)
library(cowplot)
library(BiocSingular)
library(bluster)
library(ConsensusClusterPlus)
library(gridExtra)
library(tiff)
# Marker expression, other cellular features and spatial features (co-ordinates) are read and merged into a spatial experiment object
cells =  read.csv("CellProfilerOutput/cell.csv")
dt = readRDS("RDSFiles/IMCData.rds")
# Split data into marker intensities, metadata and co-ordinates
markers = colnames(dt)[8:(length(markers)+7)]
# Load CSVs
cells = read.csv("CellProfilerOutput/cell.csv")
panel = read.csv("../raw/panel.csv")
image = read.csv("CellProfilerOutput/Image.csv")
# Filter rows and columns
image = image %>%
mutate(ROI = 1, Image = str_remove(FileName_FullStack , "_full\\.tiff")) %>%
select(-FileName_FullStack)
panel = panel %>%
dplyr::filter(trimws(Target) != "") %>%
mutate(Metal = Metal.Tag) %>%
select("Metal", "Target") %>%
dplyr::filter(Metal != "Ir191")
# Join image data with cell data
cellsCombined = left_join(cells, image, by = join_by(ImageNumber))
# Define old name and what to change to.
rename_vec = c(
"Image" = "Image",
"ImageNumber" = "ImageID",
"ROI" = "ROI",
"ObjectNumber" = "CellID",
"AreaShape_Area" = "Area",
"AreaShape_Center_X" = "X",
"AreaShape_Center_Y" = "Y")
# Change names in cellsCombined from old names to new names
names(cellsCombined) = ifelse(names(cellsCombined) %in% names(rename_vec), rename_vec[names(cellsCombined)], names(cellsCombined))
# Name marker columns
markers <- panel[,"Target"]
createSortedVector <- function(n) {
numbers <- 1:n
char_numbers <- as.character(numbers)
sorted_char_numbers <- sort(char_numbers, method = "radix")
sorted_numbers <- as.integer(sorted_char_numbers)
return(sorted_numbers)
}
ordered_markers = markers[createSortedVector(length(markers))]
colnames(cellsCombined)[6:(length(markers)+5)] = ordered_markers
# Keep only desired columns
meta = unname(sapply(strsplit(rename_vec, " = "), '[', 1))
keep = c(meta,ordered_markers)
cellsCombined = cellsCombined %>% select(all_of(keep))
cellsCombined$X = as.integer(cellsCombined$X)
cellsCombined$Y = as.integer(cellsCombined$Y)
cellsCombined$Area = as.integer(cellsCombined$Area)
dir.create("RDSFiles", showWarnings = FALSE)
saveRDS(cellsCombined, "RDSFiles/IMCData.rds")
# Marker expression, other cellular features and spatial features (co-ordinates) are read and merged into a spatial experiment object
cells =  read.csv("CellProfilerOutput/cell.csv")
dt = readRDS("RDSFiles/IMCData.rds")
# Split data into marker intensities, metadata and co-ordinates
markers = colnames(dt)[8:(length(markers)+7)]
baseCol = colnames(dt)[!(colnames(dt) %in% markers)]
baseCol = setdiff(baseCol, c("X","Y"))
counts <- dt[, markers]
meta <- dt[, baseCol]
coords <- dt[, c("X", "Y")]
# Scale data back up (if processed through cell profiler)
counts = counts*65535
# Create spatial object
spe <- SpatialExperiment(assays = list(counts = t(counts)),
colData = meta,
sample_id = as.character(meta$ImageID),
spatialCoords = as.matrix(coords))
# Set DonorID (dummy variable here)
spe$DonorID = as.factor(spe$ImageID)
# Change variables to 'factor' type
spe$Image = as.factor(spe$Image)
spe$ImageID = as.factor(spe$ImageID)
spe$ROI = as.factor(spe$ROI)
colnames(spe) = paste0(spe$ImageID, "_", spe$CellID)
# Plot current distribution
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "counts", max=10) +
ggtitle("CD3 - before transformation")
# Plot distribution after arcsinh transforming data
assay(spe, "exprs") = asinh(counts(spe))
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "exprs", max = 10) +
ggtitle("CD3 - after arcsinh transformation")
### Scale (z-transform) the arcsinh-transformed data
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store scaled expressions
scaled_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(scaled_exprs_matrix) <- channels
colnames(scaled_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to scale
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Perform Z-normalization if there are enough non-NA values
scaled_data <- scale(channel_data)
scaled_exprs_matrix[channel, image_indices] <- scaled_data
}
}
# Assign the scaled data back to the assay
assay(spe, "scaled_exprs") <- scaled_exprs_matrix
# Simple min imputation example - this replaces NA values generated by Z-norm, with the min value of that channel across all images
exprs_data <- assay(spe, "scaled_exprs")
for (i in 1:ncol(exprs_data)) {
column_values <- exprs_data[, i]
exprs_data[is.na(column_values), i] <- min(column_values, na.rm = TRUE)
}
assay(spe, "scaled_exprs") <- exprs_data
# Plot distribution after z-transforming the data
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "scaled_exprs", max=5) + ggtitle("CD3 - after z-transformation")
### Normalise values between 0 and 1 for each image
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store normalized expressions
norm_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(norm_exprs_matrix) <- channels
colnames(norm_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to normalize
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Apply min-max normalization
min_val <- min(channel_data, na.rm = TRUE)
max_val <- max(channel_data, na.rm = TRUE)
# Avoid division by zero if all values in channel_data are the same
if (range_val != 0) {
norm_data <- (channel_data - min_val) / (max_val - min_val)
} else {
norm_data <- rep(0, length(channel_data))
}
norm_exprs_matrix[channel, image_indices] <- norm_data
}
}
# Marker expression, other cellular features and spatial features (co-ordinates) are read and merged into a spatial experiment object
cells =  read.csv("CellProfilerOutput/cell.csv")
dt = readRDS("RDSFiles/IMCData.rds")
# Split data into marker intensities, metadata and co-ordinates
markers = colnames(dt)[8:(length(markers)+7)]
baseCol = colnames(dt)[!(colnames(dt) %in% markers)]
baseCol = setdiff(baseCol, c("X","Y"))
counts <- dt[, markers]
meta <- dt[, baseCol]
coords <- dt[, c("X", "Y")]
# Scale data back up (if processed through cell profiler)
counts = counts*65535
# Create spatial object
spe <- SpatialExperiment(assays = list(counts = t(counts)),
colData = meta,
sample_id = as.character(meta$ImageID),
spatialCoords = as.matrix(coords))
# Set DonorID (dummy variable here)
spe$DonorID = as.factor(spe$ImageID)
# Change variables to 'factor' type
spe$Image = as.factor(spe$Image)
spe$ImageID = as.factor(spe$ImageID)
spe$ROI = as.factor(spe$ROI)
colnames(spe) = paste0(spe$ImageID, "_", spe$CellID)
# Plot current distribution
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "counts", max=10) +
ggtitle("CD3 - before transformation")
# Plot distribution after arcsinh transforming data
assay(spe, "exprs") = asinh(counts(spe))
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "exprs", max = 10) +
ggtitle("CD3 - after arcsinh transformation")
### Scale (z-transform) the arcsinh-transformed data
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store scaled expressions
scaled_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(scaled_exprs_matrix) <- channels
colnames(scaled_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to scale
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Perform Z-normalization if there are enough non-NA values
scaled_data <- scale(channel_data)
scaled_exprs_matrix[channel, image_indices] <- scaled_data
}
}
# Assign the scaled data back to the assay
assay(spe, "scaled_exprs") <- scaled_exprs_matrix
# Simple min imputation example - this replaces NA values generated by Z-norm, with the min value of that channel across all images
exprs_data <- assay(spe, "scaled_exprs")
for (i in 1:ncol(exprs_data)) {
column_values <- exprs_data[, i]
exprs_data[is.na(column_values), i] <- min(column_values, na.rm = TRUE)
}
assay(spe, "scaled_exprs") <- exprs_data
# Plot distribution after z-transforming the data
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "scaled_exprs", max=5) + ggtitle("CD3 - after z-transformation")
### Normalise values between 0 and 1 for each image
# Extract the expression matrix and image information
exprs_matrix <- assay(spe, "exprs")
images <- spe$Image
# Get unique images and channels
unique_images <- unique(images)
channels <- rownames(exprs_matrix)
# Prepare a matrix to store normalized expressions
norm_exprs_matrix <- matrix(NA, nrow = nrow(exprs_matrix), ncol = ncol(exprs_matrix))
rownames(norm_exprs_matrix) <- channels
colnames(norm_exprs_matrix) <- colnames(exprs_matrix)
# Iterate over each image and channel to normalize
for (image in unique_images) {
image_indices <- which(images == image)
for (channel in channels) {
channel_data <- exprs_matrix[channel, image_indices]
# Apply min-max normalization
min_val <- min(channel_data, na.rm = TRUE)
max_val <- max(channel_data, na.rm = TRUE)
range_val <- max_val - min_val
# Avoid division by zero if all values in channel_data are the same
if (range_val != 0) {
norm_data <- (channel_data - min_val) / range_val
} else {
norm_data <- rep(0, length(channel_data))
}
norm_exprs_matrix[channel, image_indices] <- norm_data
}
}
# Assign the normalized data back to the assay
assay(spe, "norm_exprs") <- norm_exprs_matrix
# Plot distribution after normalising the data
dittoRidgePlot(spe, var = "CD3", group.by = "ImageID", assay = "norm_exprs", max=1.0) + ggtitle("CD3 - after normalising")
# Create an entry that specifies which markers are useful for clustering
forClust = markers
rowData(spe)$use_channel  <- rownames(spe) %in% forClust
### Assigning colour palettes
color_vectors <- list()
# DonorID
donor_ids <- unique(spe$DonorID)
# Create a color vector that repeats  if there are more than 12 unique DonorIDs
donor_colors <- brewer.pal(12, name = "Paired")[as.numeric(donor_ids) %% 12 + 1]
# Set the names of the colors to match the unique DonorIDs
DonorID <- setNames(donor_colors, donor_ids)
color_vectors$DonorID <- DonorID
# ImageID
image_ids <- unique(spe$ImageID)
# Create a color vector that repeats  if there are more than 12 unique ImageIDs
image_colors <- brewer.pal(12, name = "Paired")[as.numeric(image_ids) %% 12 + 1]
# Set the names of the colors to match the unique ImageIDs
ImageID <- setNames(image_colors, image_ids)
color_vectors$ImageID <- ImageID
metadata(spe)$color_vectors <- color_vectors
# Add a universal CellID column
colData(spe)$uCellID = 1:length(spe$CellID)
a = as.data.frame(colData(spe))
a = a %>%
group_by(Image) %>%
dplyr::filter(row_number()==1) %>%
select(Image, ImageID, uCellID)
# Write a csv with an ImageID to ImShort to Image name to uCellID key.
write.csv(a, "Image_uCellID_key.csv")
rm(a)
saveRDS(spe, "RDSFiles/spe.rds")
